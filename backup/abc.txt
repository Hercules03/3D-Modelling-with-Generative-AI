import os
import logging
import datetime

# Set tokenizers parallelism to false to avoid warnings
os.environ["TOKENIZERS_PARALLELISM"] = "false"

from dataclasses import dataclass

# LLM.py - LLM Management Module
from LLM import ModelGeneratorConfig#llm_providers dict, quit_words, settings, output_dir

#Graph components
from scad_knowledge_base import SCADKnowledgeBase
from OpenSCAD_Generator import OpenSCADGenerator
from KeywordExtractor import KeywordExtractor
from metadata_extractor import MetadataExtractor
from conversation_logger import ConversationLogger
from LLMPromptLogger import LLMPromptLogger

from graph import State
from langgraph.graph import StateGraph, START, END

logger = logging.getLogger(__name__)
logging.basicConfig(filename='debug.log', level=logging.DEBUG)
logger.info("Working on 3D_Modelling.py")

def clear_logs():
    """Clear both debug log files"""
    open('debug.log', 'w').close()
    open('detailed_debug.log', 'w').close()
    open('detailed_debug.txt', 'w').close()
    logger.info("Logs cleared for new generation")


    
@dataclass
class GenerationSettings:
    """Settings for model generation"""
    similarity_threshold: float = 0.7
    max_generation_attempts: int = 3
    default_resolution: int = 100
    min_code_length: int = 50
    max_code_length: int = 20000
    
    
    
def main():
    config = ModelGeneratorConfig(GenerationSettings())
    # Clear and initialize logging for this session
    clear_logs()
    logger.info("=" * 50)
    logger.info("Starting 3D Model Generator")
    logger.info("Time: %s", datetime.datetime.now().isoformat())
    
    print("Welcome to the 3D Model Generator!")
    
    # Ask for LLM model selection first
    print("\nAvailable LLM Providers:")
    for key, provider in config.llm_providers.items():
        print(f"{key}. {provider['name'].capitalize()} ({provider['model']})")
    
    # Selecting LLM Provider   
    while True:
        provider_choice = input("\nEnter the number of the LLM provider you want to use: ")
        if provider_choice in config.llm_providers:
            logger.info("Selected provider: %s", config.llm_providers[provider_choice]['name'])
            provider = config.llm_providers[provider_choice]
            break
        else:
            logger.warning("Invalid provider choice: %s", provider_choice)  
            print("Invalid choice. Please select 1, 2, 3, or 4.")
            continue
        
        # Check if Ollama is available for the selected provider
        if provider in ["gemma", "deepseek"]:
            logger.info("Checking Ollama availability for %s", provider['name'])
            if not OllamaManager.check_ollama(provider['name']):
                logger.warning("Ollama not available for %s. Switching to default provider.", provider['name'])
                provider = config.llm_providers['1']
        
        logger.info("Initializing generator with provider: %s", provider['name'])
        break
    
    # Initialize different components
    conversation_logger = ConversationLogger()
    prompt_logger = LLMPromptLogger()
    keyword_extractor = KeywordExtractor()
    metadata_extractor = MetadataExtractor(provider, conversation_logger, prompt_logger)
    kb = SCADKnowledgeBase(keyword_extractor, metadata_extractor, conversation_logger)
    generator = OpenSCADGenerator(provider, knowledge_base=kb, keyword_extractor=keyword_extractor, metadata_extractor=metadata_extractor, conversation_logger=conversation_logger)
    
    # Action selection
    while True:
        print("\nSelect an option:")
        print("1. Generate a 3D object")
        print("2. Input knowledge manually")
        print("3. Delete knowledge")
        print("4. View knowledge base")
        print("5. Quit")
        
        action_choice = input("\nEnter your choice (1-5): ").strip()
        
        if action_choice == "5" or action_choice.lower() in config.quit_words:  #Quit
            # Log final summary before exiting
            logger.info("User decided to quit the application")
            logger.info("\nSession Summary:")
            logger.info("Session ended at: %s", datetime.datetime.now().isoformat())
            logger.info("=" * 50)
            
            print("\nGoodbye!")
            break
        
        elif action_choice == "2":  #Manual Knowledge Input
            pass
        
        elif action_choice == "3":  #Knowledge Deletion
            logger.info("Starting knowledge deletion")
            result = kb.delete_knowledge()
            logger.info("Knowledge deletion result: %s", "Success" if result else "Failed")
            continue
        
        elif action_choice == "4":  #Knowledge Base Viewer
            logger.info("Starting knowledge base viewer")
            kb.get_all_examples(interactive=True)
            logger.info("Knowledge base viewing completed")
            continue
        
        elif action_choice == "1":  #Generate 3D Object
            graph_builder = StateGraph(State)
            graph_builder.add_node("user_query", user_query)  # Simply store the raw query
            
            graph_builder.add_edge(START, "user_query")
            
            graph_builder.add_edge("user_query", END)
            
            graph_builder.compile()
            
            graph_builder.run(user_query)
            
                
if __name__ == "__main__":
    main()